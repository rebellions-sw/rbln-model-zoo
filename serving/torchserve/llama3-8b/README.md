# Llama3-8B with Continous Batching 
Supplementary guide for the tutorial on serving LLMs with the TorchServe

# Files
- material
  - Contains the source files extracted from the document page, used in this tutorial.
- check_env.sh
  - A Bash script to verify all necessary preparations for running this tutorial properly.
- setup.sh
  - A setup script for preparing the required files and configurations for this tutorial.

# Result
You can check the `output` directory, which contains all the necessary preparations for running the tutorial.

# References
[Llama3-8B with Continous Batching](https://docs.rbln.ai/software/model_serving/torchserve/tutorial/llama3-8B_continuous_batching.html)
